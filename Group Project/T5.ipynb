{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDYo500GP0lF"
   },
   "source": [
    "**Some references**\n",
    "\n",
    "https://www.kaggle.com/code/minhsienweng/train-infer-pii-detection-deberta-v3\n",
    "\n",
    "(no training) https://www.kaggle.com/code/manavtrivedi/0-967-nlp-sakura/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n6__3vASP0lG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datasets\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer, TrainingArguments\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ignite.metrics import Fbeta\n",
    "from functools import partial\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.nn.functional import softmax\n",
    "from peft import get_peft_model, LoraConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4uvLtUhP0lH"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN2eOKHyP0lH",
    "outputId": "eec8a107-44c8-4386-d70d-d67d131128f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 labels, with the following labels:\n",
      " ['I-NAME_STUDENT', 'O', 'I-URL_PERSONAL', 'I-STREET_ADDRESS', 'B-EMAIL', 'B-STREET_ADDRESS', 'B-NAME_STUDENT', 'B-ID_NUM', 'B-USERNAME', 'I-PHONE_NUM', 'I-ID_NUM', 'B-PHONE_NUM', 'B-URL_PERSONAL']\n"
     ]
    }
   ],
   "source": [
    "#Finding out the number of labels\n",
    "data = json.load(open('data/train.json'))\n",
    "\n",
    "all_labels = set()\n",
    "\n",
    "for d in data:\n",
    "    all_labels = all_labels.union(set(d['labels']))\n",
    "\n",
    "print(f\"{len(list(all_labels))} labels, with the following labels:\\n {list(all_labels)}\")\n",
    "del data\n",
    "\n",
    "label2id = {label:index for index,label in enumerate(all_labels)}\n",
    "id2label = {index:label for index,label in enumerate(all_labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IcQlTdmP0lH",
    "outputId": "41b36350-60bb-4b7d-ba05-a63e3b2732a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-NAME_STUDENT', 'O', 'I-URL_PERSONAL', 'I-STREET_ADDRESS', 'B-EMAIL', 'B-STREET_ADDRESS', 'B-NAME_STUDENT', 'B-ID_NUM', 'B-USERNAME', 'I-PHONE_NUM', 'I-ID_NUM', 'B-PHONE_NUM', 'B-URL_PERSONAL'}\n"
     ]
    }
   ],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kXBrx4JcP0lH"
   },
   "outputs": [],
   "source": [
    "#Change to one-hot vector\n",
    "def oh_encoder(labels):  #label: array of output for each sentence\n",
    "\n",
    "    # unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-PHONE_NUM', 'I-PHONE_NUM','B-ID_NUM', 'I-ID_NUM',  'B-URL_PERSONAL','I-URL_PERSONAL',\n",
    "    #                   'B-STREET_ADDRESS', 'I-STREET_ADDRESS',  'B-EMAIL', 'B-USERNAME']\n",
    "\n",
    "\n",
    "    unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-URL_PERSONAL', 'B-ID_NUM','I-ID_NUM','B-EMAIL','I-STREET_ADDRESS',\n",
    "                     'I-PHONE_NUM', 'B-USERNAME', 'B-PHONE_NUM','B-STREET_ADDRESS', 'I-URL_PERSONAL']\n",
    "\n",
    "    labels_oh = []\n",
    "    for label in labels:    #label: str\n",
    "        label_oh = [float(0)]*len(unique_labels)\n",
    "        for k in range(len(unique_labels)):\n",
    "            if unique_labels[k] == label:\n",
    "                label_oh[k] = 1\n",
    "                #labels_oh.append(torch.tensor(label_oh, requires_grad=True))\n",
    "                labels_oh.append(label_oh)\n",
    "                break\n",
    "\n",
    "\n",
    "    #return torch.tensor(labels_oh, requires_grad=True)\n",
    "    return torch.tensor(labels_oh, requires_grad=True, dtype=float)    #list of one-hot labels as tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OT7GO72UP0lH"
   },
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer):\n",
    "    import numpy as np\n",
    "    # Preprocess the tokens and labels by adding trailing whitespace and labels\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for token, label, t_ws in zip(example[\"tokens\"],\n",
    "                                  example[\"labels\"],\n",
    "                                  example[\"trailing_whitespace\"]):\n",
    "        tokens.append(token)\n",
    "        labels.extend([label] * len(token))\n",
    "        # Added trailing whitespace and label if true and\n",
    "        if t_ws:\n",
    "            tokens.append(\" \")\n",
    "            # labels.append(oh_encoder(\"O\"))\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    text = \"\".join(tokens)\n",
    "    # print(f\"len(text)={len(text)}, len(tokens)={len(tokens)}\")\n",
    "    # tokenization without truncation\n",
    "    tokenized = tokenizer(text, return_offsets_mapping=True,\n",
    "                          truncation=False)\n",
    "    #labels = np.array(labels)\n",
    "    # Labels\n",
    "    token_labels = []\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # Added 'O'\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            #token_labels.append(label2id[\"O\"])\n",
    "            #token_labels.append(oh_encoder(\"O\"))\n",
    "            token_labels.append(\"O\")\n",
    "        else:\n",
    "            # case when the text starts with whitespace\n",
    "            if text[start_idx].isspace():\n",
    "                start_idx += 1\n",
    "            # Convert label to id (int)\n",
    "            #label_id = label2id[labels[start_idx]]\n",
    "            label_id = labels[start_idx]\n",
    "            #token_labels.append(oh_encoder(label_id))\n",
    "            token_labels.append(label_id)\n",
    "\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": len(tokenized.input_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ku5VDtwbP0lI"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(outputs, labels, unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-URL_PERSONAL',\n",
    "                                                          'B-ID_NUM','I-ID_NUM','B-EMAIL','I-STREET_ADDRESS',\n",
    "                                                          'I-PHONE_NUM', 'B-USERNAME', 'B-PHONE_NUM','B-STREET_ADDRESS', 'I-URL_PERSONAL']):\n",
    "    try:\n",
    "        #print(\"Compute metrics\")\n",
    "        predictions = torch.argmax(softmax(outputs, dim=2), dim=2)\n",
    "        # Include prediction Remove ignored index (special tokens)\n",
    "        true_preds = []\n",
    "        true_labels = []\n",
    "        for pred, label in zip(predictions, labels):\n",
    "            true_preds.append([unique_labels[p] for p, l in zip(pred, label) if l[0] != -100])\n",
    "            true_labels.append([unique_labels[torch.argmax(l)] for p, l in zip(pred, label) if l[0] != -100])\n",
    "\n",
    "        mlb = MultiLabelBinarizer(classes=unique_labels)\n",
    "        true_preds_bin = mlb.fit_transform(true_preds)\n",
    "        true_labels_bin = mlb.transform(true_labels)\n",
    "        # Compute recall, precision and f5 score\n",
    "        recall = recall_score(true_labels_bin, true_preds_bin, average='samples')\n",
    "        precision = precision_score(true_labels_bin, true_preds_bin, average='samples')\n",
    "        # Use modified f5 score to measure the performance\n",
    "        f5_score = (1 + 5*5) * (recall * precision / (5*5*precision + recall))\n",
    "        result = {'f5': f5_score,\n",
    "                  'recall': recall,\n",
    "                  'precision': precision}\n",
    "        # print(f\"result = {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a03sd6GBP0lI"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, num_classes=len(all_labels)):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        mask = (targets != -100).float()\n",
    "        targets = targets.clamp(min=0)\n",
    "        #targets = F.one_hot(targets, num_classes=self.num_classes).float()\n",
    "\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        # F_loss = F_loss.mean(dim=1)\n",
    "        F_loss = torch.mul(F_loss, mask).mean(dim=1)\n",
    "\n",
    "        return F_loss.sum()/mask.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5zeNl1HP0lI"
   },
   "source": [
    "# Model: T5\n",
    "\n",
    "Using a pretrained T5 (small), we will build a classifier head on top of it to predict the class at token level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI7jZvuQP0lI"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vXLDcy9pZrBC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForTokenClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBAhWUTBP0lI",
    "outputId": "4eafc62e-48c6-4a59-d09d-403222361bbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at google-t5/t5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at google-t5/t5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's trainable parameters:  1,579,533\n",
      "Model's total parameters:  36,910,349\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "#config = T5ForTokenClassification.from_pretrained(\"google-t5/t5-small\").config\n",
    "\n",
    "config = AutoModelForTokenClassification.from_pretrained(\"google-t5/t5-small\").config\n",
    "\n",
    "config.update({'num_labels': 13})\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"FEATURE_EXTRACTION\",\n",
    "        inference_mode=False,\n",
    "        target_modules = ['q', 'k', 'v', 'o'])\n",
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#                 load_in_4bit=True,\n",
    "#                 bnb_4bit_quant_type=\"nf4\",\n",
    "#                 bnb_4bit_use_double_quant=False,\n",
    "#                 bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#                 llm_int8_skip_modules=['classifier']\n",
    "#             )\n",
    "\n",
    "#bnb_config = BitsAndBytesConfig(\n",
    " #       load_in_8bit=True,\n",
    "  #      llm_int8_skip_modules=['classifier']\n",
    "#)\n",
    "\n",
    "#model = T5ForTokenClassification.from_pretrained(\"google-t5/t5-small\", ignore_mismatched_sizes=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"google-t5/t5-small\", config = config,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "                                                        #quantization_config=bnb_config)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Model's trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad): ,}\")\n",
    "print(f\"Model's total parameters: {sum(p.numel() for p in model.parameters()): ,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForTokenClassification(\n",
       "  (transformer): T5EncoderModel(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QQfqGCkvP0lJ"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "epochs = 5\n",
    "##tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of = 32, max_length=3500)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "#criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "f2206b9a9fe641b9a723f30b07a1e435",
      "08839243a92f4a55a9c79573c54e34e9",
      "7f850617a1244e8c847599cfe3d9864d",
      "bbd2e8350d8a432da85cf9d1a2c183dd",
      "d43e2ac16a734dda8a0e918c463c1ad2",
      "aec0dd539324488ab0bda7e20fb5e4ee",
      "6c5a6c4de11a4cdca36b842148ff1f60",
      "c80fbe0e7ccc49cca7545def9ae6d0f9",
      "5c23a733d360454087c8b51862ef2573",
      "934d8a50afe94ec5aa281a71a0dd835f",
      "baa2afc3a2724969b0b170403e0f96d0",
      "7b75520d32464159aaf1df18a5d79557",
      "2845269df4af4d969f55ff24fcb22d6c",
      "633cf20038dd4c2a83c54f3bc83c076b",
      "b3550a6e502e4a879d976b058aee08f4",
      "a5949a52513341a8bcefec74813a0975",
      "a140a9d5f8494b74aae44b6559a35612",
      "ef189afc4e064787a1ad4f503dc66f77",
      "c3992ca9a85849ea9b807e6d2f36120a",
      "658044d033914f9f8899b08733afd0a7",
      "c7ed24318c5d44adb938faf7353c47a6",
      "07234c7b51544c27a05ecffa91cddfbb"
     ]
    },
    "id": "NetdKIPqP0lJ",
    "outputId": "ad07fbb1-39e4-468e-e24d-954afbea8b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed\n",
      "trainset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|██████████| 5785/5785 [00:11<00:00, 503.30 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset mapped\n",
      "valset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|██████████| 1022/1022 [00:04<00:00, 231.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valset mapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Preparing the datasets for token classification\n",
    "data = json.load(open('data/train.json'))\n",
    "##model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "##tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.15, random_state=42)\n",
    "print('Data split completed')\n",
    "\n",
    "# # Limit to 100 for testing\n",
    "#train_data = train_data[:100]\n",
    "#val_data = val_data[:100]\n",
    "\n",
    "trainset = datasets.Dataset.from_dict({\n",
    "    'full_text': [x['full_text'] for x in train_data],\n",
    "    'document': [x['document'] for x in train_data],\n",
    "    'tokens': [x['tokens'] for x in train_data],\n",
    "    'trailing_whitespace': [x['trailing_whitespace'] for x in train_data],\n",
    "    'labels' :[x['labels'] for x in train_data]\n",
    "    # 'labels' :[oh_encoder(x['labels']) for x in train_data]\n",
    "})\n",
    "print('trainset loaded')\n",
    "\n",
    "trainset = trainset.map(tokenize, fn_kwargs = {\"tokenizer\": tokenizer}, num_proc=3)\n",
    "#train_labels = [oh_encoder(x['labels'] for x in train_data)]\n",
    "print('trainset mapped')\n",
    "\n",
    "# val_labels = [oh_encoder(x['labels']) for x in val_data]\n",
    "\n",
    "valset = datasets.Dataset.from_dict({\n",
    "    'full_text': [x['full_text'] for x in val_data],\n",
    "    'document': [x['document'] for x in val_data],\n",
    "    'tokens': [x['tokens'] for x in val_data],\n",
    "    'trailing_whitespace': [x['trailing_whitespace'] for x in val_data],\n",
    "    'labels' :[x['labels'] for x in val_data]\n",
    "    # 'labels' :[oh_encoder(x['labels']) for x in val_data]\n",
    "})\n",
    "print('valset loaded')\n",
    "\n",
    "valset = valset.map(tokenize, fn_kwargs = {\"tokenizer\": tokenizer}, num_proc=3)\n",
    "print('valset mapped')\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcTRlA6mP0lJ",
    "outputId": "6db63258-4a3d-43e9-93d8-52585f367f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 5785 || Number of validation data: 1022\n"
     ]
    }
   ],
   "source": [
    "#First item\n",
    "print(f\"Number of training data: {len(trainset)} || Number of validation data: {len(valset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WeMMxTvFP0lJ",
    "outputId": "45fab912-97a6-4140-806f-7e7971b53a8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not Required'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Not Required'''\n",
    "# def to_dict(data):\n",
    "#     dict_of_lists = {}\n",
    "#     for d in data:\n",
    "#         for key, value in d.items():\n",
    "#             if key in dict_of_lists:\n",
    "#                 dict_of_lists[key].append(value)\n",
    "#             else:\n",
    "#                 dict_of_lists[key] = [value]\n",
    "#     return dict_of_lists\n",
    "\n",
    "# trainset = to_dict(trainset)\n",
    "# #trainset['labels'] = train_labels\n",
    "\n",
    "# valset = to_dict(valset)\n",
    "# #valset['labels'] = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Hg9Ae3I8P0lJ"
   },
   "outputs": [],
   "source": [
    "class Custom_data(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        self.data = data_dict['input_ids']\n",
    "        self.attention_mask = data_dict['attention_mask']\n",
    "        self.labels = data_dict['labels']\n",
    "        self.doc_no = data_dict['document']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.attention_mask[idx]), oh_encoder(self.labels[idx]) , torch.tensor(self.doc_no[idx])\n",
    "\n",
    "custom_train = Custom_data(trainset)\n",
    "custom_val = Custom_data(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EsQgSgABP0lJ"
   },
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    '''\n",
    "    For padding\n",
    "    '''\n",
    "    input_ids, attention_mask, one_hot_labels, document = zip(*batch)\n",
    "    # Pad the input_ids and labels\n",
    "    padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    padded_attention_mask = pad_sequence(attention_mask, batch_first = True, padding_value = 0)\n",
    "    padded_labels = pad_sequence(one_hot_labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "    return padded_input_ids, padded_attention_mask, padded_labels, document\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(custom_train, batch_size=batch_size, collate_fn = custom_collate)\n",
    "val_dataloader = DataLoader(custom_val, batch_size=batch_size, collate_fn=custom_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7IK7e-koE6u",
    "outputId": "0e05dbf5-66c6-4f63-e21a-004d7f5d2ade",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Input IDs: torch.Size([8, 1010])\n",
      "Attention_mask: torch.Size([8, 1010])\n",
      "Labels: torch.Size([8, 1010, 13])\n",
      "Document: (tensor(17809), tensor(11144), tensor(16158), tensor(9980), tensor(17676), tensor(20173), tensor(10494), tensor(14012))\n",
      "\n",
      "Batch 2:\n",
      "Input IDs: torch.Size([8, 1395])\n",
      "Attention_mask: torch.Size([8, 1395])\n",
      "Labels: torch.Size([8, 1395, 13])\n",
      "Document: (tensor(8593), tensor(22104), tensor(20242), tensor(10762), tensor(20529), tensor(4899), tensor(8849), tensor(13131))\n",
      "\n",
      "Batch 3:\n",
      "Input IDs: torch.Size([8, 2212])\n",
      "Attention_mask: torch.Size([8, 2212])\n",
      "Labels: torch.Size([8, 2212, 13])\n",
      "Document: (tensor(15076), tensor(13209), tensor(8612), tensor(16882), tensor(16916), tensor(20336), tensor(21008), tensor(10877))\n",
      "\n",
      "Batch 4:\n",
      "Input IDs: torch.Size([8, 1524])\n",
      "Attention_mask: torch.Size([8, 1524])\n",
      "Labels: torch.Size([8, 1524, 13])\n",
      "Document: (tensor(8229), tensor(17787), tensor(19041), tensor(16583), tensor(11136), tensor(17544), tensor(3686), tensor(13706))\n",
      "\n",
      "Batch 5:\n",
      "Input IDs: torch.Size([8, 1247])\n",
      "Attention_mask: torch.Size([8, 1247])\n",
      "Labels: torch.Size([8, 1247, 13])\n",
      "Document: (tensor(4936), tensor(15226), tensor(19425), tensor(11068), tensor(8491), tensor(21598), tensor(22261), tensor(9134))\n",
      "\n",
      "Batch 6:\n",
      "Input IDs: torch.Size([8, 1055])\n",
      "Attention_mask: torch.Size([8, 1055])\n",
      "Labels: torch.Size([8, 1055, 13])\n",
      "Document: (tensor(20222), tensor(4214), tensor(18259), tensor(11939), tensor(14583), tensor(12641), tensor(19348), tensor(10446))\n",
      "\n",
      "Batch 7:\n",
      "Input IDs: torch.Size([8, 2780])\n",
      "Attention_mask: torch.Size([8, 2780])\n",
      "Labels: torch.Size([8, 2780, 13])\n",
      "Document: (tensor(13474), tensor(22141), tensor(7745), tensor(8545), tensor(14866), tensor(9219), tensor(2995), tensor(22518))\n",
      "\n",
      "Batch 8:\n",
      "Input IDs: torch.Size([8, 1023])\n",
      "Attention_mask: torch.Size([8, 1023])\n",
      "Labels: torch.Size([8, 1023, 13])\n",
      "Document: (tensor(17405), tensor(8794), tensor(22192), tensor(11984), tensor(9362), tensor(19937), tensor(13447), tensor(22154))\n",
      "\n",
      "Batch 9:\n",
      "Input IDs: torch.Size([8, 2324])\n",
      "Attention_mask: torch.Size([8, 2324])\n",
      "Labels: torch.Size([8, 2324, 13])\n",
      "Document: (tensor(20660), tensor(21932), tensor(12027), tensor(16157), tensor(10559), tensor(5001), tensor(13697), tensor(10483))\n",
      "\n",
      "Batch 10:\n",
      "Input IDs: torch.Size([8, 1234])\n",
      "Attention_mask: torch.Size([8, 1234])\n",
      "Labels: torch.Size([8, 1234, 13])\n",
      "Document: (tensor(8989), tensor(13638), tensor(14521), tensor(13695), tensor(11491), tensor(22167), tensor(10540), tensor(11807))\n",
      "\n",
      "Batch 11:\n",
      "Input IDs: torch.Size([8, 1538])\n",
      "Attention_mask: torch.Size([8, 1538])\n",
      "Labels: torch.Size([8, 1538, 13])\n",
      "Document: (tensor(16243), tensor(21826), tensor(17035), tensor(1325), tensor(20384), tensor(14606), tensor(16391), tensor(15062))\n",
      "\n",
      "Batch 12:\n",
      "Input IDs: torch.Size([8, 1027])\n",
      "Attention_mask: torch.Size([8, 1027])\n",
      "Labels: torch.Size([8, 1027, 13])\n",
      "Document: (tensor(13083), tensor(12857), tensor(12009), tensor(22190), tensor(22075), tensor(20708), tensor(17011), tensor(11443))\n",
      "\n",
      "Batch 13:\n",
      "Input IDs: torch.Size([8, 1399])\n",
      "Attention_mask: torch.Size([8, 1399])\n",
      "Labels: torch.Size([8, 1399, 13])\n",
      "Document: (tensor(18449), tensor(19274), tensor(10978), tensor(10194), tensor(16659), tensor(13763), tensor(10373), tensor(19738))\n",
      "\n",
      "Batch 14:\n",
      "Input IDs: torch.Size([8, 1550])\n",
      "Attention_mask: torch.Size([8, 1550])\n",
      "Labels: torch.Size([8, 1550, 13])\n",
      "Document: (tensor(13527), tensor(14132), tensor(22466), tensor(21867), tensor(21266), tensor(17188), tensor(6769), tensor(19163))\n",
      "\n",
      "Batch 15:\n",
      "Input IDs: torch.Size([8, 1561])\n",
      "Attention_mask: torch.Size([8, 1561])\n",
      "Labels: torch.Size([8, 1561, 13])\n",
      "Document: (tensor(16089), tensor(11450), tensor(18930), tensor(9494), tensor(15333), tensor(17607), tensor(9560), tensor(16216))\n",
      "\n",
      "Batch 16:\n",
      "Input IDs: torch.Size([8, 1225])\n",
      "Attention_mask: torch.Size([8, 1225])\n",
      "Labels: torch.Size([8, 1225, 13])\n",
      "Document: (tensor(11303), tensor(14563), tensor(18011), tensor(16952), tensor(13542), tensor(7176), tensor(13082), tensor(13936))\n",
      "\n",
      "Batch 17:\n",
      "Input IDs: torch.Size([8, 1850])\n",
      "Attention_mask: torch.Size([8, 1850])\n",
      "Labels: torch.Size([8, 1850, 13])\n",
      "Document: (tensor(16031), tensor(4317), tensor(11145), tensor(19812), tensor(10891), tensor(21034), tensor(12538), tensor(19712))\n",
      "\n",
      "Batch 18:\n",
      "Input IDs: torch.Size([8, 986])\n",
      "Attention_mask: torch.Size([8, 986])\n",
      "Labels: torch.Size([8, 986, 13])\n",
      "Document: (tensor(20815), tensor(22329), tensor(17057), tensor(20850), tensor(15939), tensor(15513), tensor(12899), tensor(8762))\n",
      "\n",
      "Batch 19:\n",
      "Input IDs: torch.Size([8, 1657])\n",
      "Attention_mask: torch.Size([8, 1657])\n",
      "Labels: torch.Size([8, 1657, 13])\n",
      "Document: (tensor(10885), tensor(10220), tensor(11117), tensor(19358), tensor(22622), tensor(20108), tensor(11761), tensor(17362))\n",
      "\n",
      "Batch 20:\n",
      "Input IDs: torch.Size([8, 1133])\n",
      "Attention_mask: torch.Size([8, 1133])\n",
      "Labels: torch.Size([8, 1133, 13])\n",
      "Document: (tensor(21712), tensor(10097), tensor(13066), tensor(7548), tensor(18347), tensor(8787), tensor(11644), tensor(13060))\n",
      "\n",
      "Batch 21:\n",
      "Input IDs: torch.Size([8, 1336])\n",
      "Attention_mask: torch.Size([8, 1336])\n",
      "Labels: torch.Size([8, 1336, 13])\n",
      "Document: (tensor(20399), tensor(14775), tensor(20640), tensor(20758), tensor(10882), tensor(16024), tensor(12585), tensor(14155))\n",
      "\n",
      "Batch 22:\n",
      "Input IDs: torch.Size([8, 1067])\n",
      "Attention_mask: torch.Size([8, 1067])\n",
      "Labels: torch.Size([8, 1067, 13])\n",
      "Document: (tensor(14080), tensor(19555), tensor(14767), tensor(11501), tensor(17969), tensor(19503), tensor(20892), tensor(16180))\n",
      "\n",
      "Batch 23:\n",
      "Input IDs: torch.Size([8, 1012])\n",
      "Attention_mask: torch.Size([8, 1012])\n",
      "Labels: torch.Size([8, 1012, 13])\n",
      "Document: (tensor(10418), tensor(15053), tensor(18883), tensor(22362), tensor(12384), tensor(19018), tensor(12869), tensor(15205))\n",
      "\n",
      "Batch 24:\n",
      "Input IDs: torch.Size([8, 1920])\n",
      "Attention_mask: torch.Size([8, 1920])\n",
      "Labels: torch.Size([8, 1920, 13])\n",
      "Document: (tensor(18552), tensor(16966), tensor(17648), tensor(10995), tensor(11436), tensor(13520), tensor(9802), tensor(19912))\n",
      "\n",
      "Batch 25:\n",
      "Input IDs: torch.Size([8, 1125])\n",
      "Attention_mask: torch.Size([8, 1125])\n",
      "Labels: torch.Size([8, 1125, 13])\n",
      "Document: (tensor(21460), tensor(10624), tensor(17751), tensor(14488), tensor(10028), tensor(13883), tensor(20641), tensor(13090))\n",
      "\n",
      "Batch 26:\n",
      "Input IDs: torch.Size([8, 1438])\n",
      "Attention_mask: torch.Size([8, 1438])\n",
      "Labels: torch.Size([8, 1438, 13])\n",
      "Document: (tensor(20135), tensor(12675), tensor(12276), tensor(15430), tensor(21426), tensor(20562), tensor(9050), tensor(10301))\n",
      "\n",
      "Batch 27:\n",
      "Input IDs: torch.Size([8, 1154])\n",
      "Attention_mask: torch.Size([8, 1154])\n",
      "Labels: torch.Size([8, 1154, 13])\n",
      "Document: (tensor(22111), tensor(9726), tensor(18048), tensor(10730), tensor(10112), tensor(13941), tensor(22577), tensor(21003))\n",
      "\n",
      "Batch 28:\n",
      "Input IDs: torch.Size([8, 989])\n",
      "Attention_mask: torch.Size([8, 989])\n",
      "Labels: torch.Size([8, 989, 13])\n",
      "Document: (tensor(7408), tensor(21834), tensor(17234), tensor(10755), tensor(7770), tensor(1753), tensor(11753), tensor(21457))\n",
      "\n",
      "Batch 29:\n",
      "Input IDs: torch.Size([8, 1396])\n",
      "Attention_mask: torch.Size([8, 1396])\n",
      "Labels: torch.Size([8, 1396, 13])\n",
      "Document: (tensor(15751), tensor(16129), tensor(19171), tensor(16311), tensor(9106), tensor(9964), tensor(13288), tensor(20495))\n",
      "\n",
      "Batch 30:\n",
      "Input IDs: torch.Size([8, 1157])\n",
      "Attention_mask: torch.Size([8, 1157])\n",
      "Labels: torch.Size([8, 1157, 13])\n",
      "Document: (tensor(20198), tensor(19900), tensor(10668), tensor(12003), tensor(7708), tensor(15262), tensor(18536), tensor(18374))\n",
      "\n",
      "Batch 31:\n",
      "Input IDs: torch.Size([8, 1546])\n",
      "Attention_mask: torch.Size([8, 1546])\n",
      "Labels: torch.Size([8, 1546, 13])\n",
      "Document: (tensor(330), tensor(5935), tensor(14113), tensor(19481), tensor(17984), tensor(9314), tensor(17806), tensor(21217))\n",
      "\n",
      "Batch 32:\n",
      "Input IDs: torch.Size([8, 1733])\n",
      "Attention_mask: torch.Size([8, 1733])\n",
      "Labels: torch.Size([8, 1733, 13])\n",
      "Document: (tensor(9301), tensor(14071), tensor(18018), tensor(4765), tensor(12260), tensor(12998), tensor(11177), tensor(9021))\n",
      "\n",
      "Batch 33:\n",
      "Input IDs: torch.Size([8, 1357])\n",
      "Attention_mask: torch.Size([8, 1357])\n",
      "Labels: torch.Size([8, 1357, 13])\n",
      "Document: (tensor(18053), tensor(14599), tensor(16869), tensor(9943), tensor(19500), tensor(14403), tensor(5083), tensor(16467))\n",
      "\n",
      "Batch 34:\n",
      "Input IDs: torch.Size([8, 1265])\n",
      "Attention_mask: torch.Size([8, 1265])\n",
      "Labels: torch.Size([8, 1265, 13])\n",
      "Document: (tensor(15493), tensor(18922), tensor(15045), tensor(22227), tensor(13271), tensor(13437), tensor(21922), tensor(21966))\n",
      "\n",
      "Batch 35:\n",
      "Input IDs: torch.Size([8, 1596])\n",
      "Attention_mask: torch.Size([8, 1596])\n",
      "Labels: torch.Size([8, 1596, 13])\n",
      "Document: (tensor(17916), tensor(11412), tensor(12271), tensor(19722), tensor(9973), tensor(18643), tensor(12823), tensor(20672))\n",
      "\n",
      "Batch 36:\n",
      "Input IDs: torch.Size([8, 1272])\n",
      "Attention_mask: torch.Size([8, 1272])\n",
      "Labels: torch.Size([8, 1272, 13])\n",
      "Document: (tensor(12366), tensor(11389), tensor(11469), tensor(19206), tensor(14313), tensor(21669), tensor(651), tensor(16900))\n",
      "\n",
      "Batch 37:\n",
      "Input IDs: torch.Size([8, 1029])\n",
      "Attention_mask: torch.Size([8, 1029])\n",
      "Labels: torch.Size([8, 1029, 13])\n",
      "Document: (tensor(14193), tensor(21222), tensor(8076), tensor(16532), tensor(18507), tensor(21578), tensor(10798), tensor(22435))\n",
      "\n",
      "Batch 38:\n",
      "Input IDs: torch.Size([8, 1432])\n",
      "Attention_mask: torch.Size([8, 1432])\n",
      "Labels: torch.Size([8, 1432, 13])\n",
      "Document: (tensor(14926), tensor(317), tensor(2882), tensor(13815), tensor(9255), tensor(15719), tensor(12249), tensor(19952))\n",
      "\n",
      "Batch 39:\n",
      "Input IDs: torch.Size([8, 1126])\n",
      "Attention_mask: torch.Size([8, 1126])\n",
      "Labels: torch.Size([8, 1126, 13])\n",
      "Document: (tensor(16394), tensor(19235), tensor(10770), tensor(20006), tensor(20474), tensor(19929), tensor(21730), tensor(14817))\n",
      "\n",
      "Batch 40:\n",
      "Input IDs: torch.Size([8, 972])\n",
      "Attention_mask: torch.Size([8, 972])\n",
      "Labels: torch.Size([8, 972, 13])\n",
      "Document: (tensor(12481), tensor(19265), tensor(18377), tensor(2694), tensor(12649), tensor(17158), tensor(12437), tensor(17752))\n",
      "\n",
      "Batch 41:\n",
      "Input IDs: torch.Size([8, 1043])\n",
      "Attention_mask: torch.Size([8, 1043])\n",
      "Labels: torch.Size([8, 1043, 13])\n",
      "Document: (tensor(13854), tensor(12876), tensor(11590), tensor(9345), tensor(14393), tensor(16009), tensor(19429), tensor(14447))\n",
      "\n",
      "Batch 42:\n",
      "Input IDs: torch.Size([8, 1371])\n",
      "Attention_mask: torch.Size([8, 1371])\n",
      "Labels: torch.Size([8, 1371, 13])\n",
      "Document: (tensor(12294), tensor(9600), tensor(2813), tensor(19861), tensor(22288), tensor(7929), tensor(11854), tensor(22309))\n",
      "\n",
      "Batch 43:\n",
      "Input IDs: torch.Size([8, 1122])\n",
      "Attention_mask: torch.Size([8, 1122])\n",
      "Labels: torch.Size([8, 1122, 13])\n",
      "Document: (tensor(760), tensor(22477), tensor(21372), tensor(18757), tensor(9290), tensor(9157), tensor(14978), tensor(21819))\n",
      "\n",
      "Batch 44:\n",
      "Input IDs: torch.Size([8, 1392])\n",
      "Attention_mask: torch.Size([8, 1392])\n",
      "Labels: torch.Size([8, 1392, 13])\n",
      "Document: (tensor(9508), tensor(22313), tensor(9040), tensor(10485), tensor(21647), tensor(16224), tensor(14846), tensor(19435))\n",
      "\n",
      "Batch 45:\n",
      "Input IDs: torch.Size([8, 1144])\n",
      "Attention_mask: torch.Size([8, 1144])\n",
      "Labels: torch.Size([8, 1144, 13])\n",
      "Document: (tensor(10481), tensor(15459), tensor(5271), tensor(12757), tensor(11461), tensor(19797), tensor(14218), tensor(10600))\n",
      "\n",
      "Batch 46:\n",
      "Input IDs: torch.Size([8, 2145])\n",
      "Attention_mask: torch.Size([8, 2145])\n",
      "Labels: torch.Size([8, 2145, 13])\n",
      "Document: (tensor(21955), tensor(15300), tensor(6088), tensor(11901), tensor(14327), tensor(14604), tensor(14621), tensor(10845))\n",
      "\n",
      "Batch 47:\n",
      "Input IDs: torch.Size([8, 1823])\n",
      "Attention_mask: torch.Size([8, 1823])\n",
      "Labels: torch.Size([8, 1823, 13])\n",
      "Document: (tensor(375), tensor(9823), tensor(22150), tensor(15868), tensor(21349), tensor(13892), tensor(11102), tensor(22536))\n",
      "\n",
      "Batch 48:\n",
      "Input IDs: torch.Size([8, 1039])\n",
      "Attention_mask: torch.Size([8, 1039])\n",
      "Labels: torch.Size([8, 1039, 13])\n",
      "Document: (tensor(9086), tensor(9103), tensor(9864), tensor(22093), tensor(21318), tensor(15259), tensor(11123), tensor(13368))\n",
      "\n",
      "Batch 49:\n",
      "Input IDs: torch.Size([8, 899])\n",
      "Attention_mask: torch.Size([8, 899])\n",
      "Labels: torch.Size([8, 899, 13])\n",
      "Document: (tensor(19092), tensor(11339), tensor(17813), tensor(14855), tensor(15741), tensor(22216), tensor(8485), tensor(11952))\n",
      "\n",
      "Batch 50:\n",
      "Input IDs: torch.Size([8, 679])\n",
      "Attention_mask: torch.Size([8, 679])\n",
      "Labels: torch.Size([8, 679, 13])\n",
      "Document: (tensor(22415), tensor(15701), tensor(9571), tensor(14576), tensor(13503), tensor(14587), tensor(19768), tensor(13282))\n",
      "\n",
      "Batch 51:\n",
      "Input IDs: torch.Size([8, 2190])\n",
      "Attention_mask: torch.Size([8, 2190])\n",
      "Labels: torch.Size([8, 2190, 13])\n",
      "Document: (tensor(20651), tensor(11105), tensor(20274), tensor(19363), tensor(7256), tensor(6595), tensor(15533), tensor(20170))\n",
      "\n",
      "Batch 52:\n",
      "Input IDs: torch.Size([8, 1560])\n",
      "Attention_mask: torch.Size([8, 1560])\n",
      "Labels: torch.Size([8, 1560, 13])\n",
      "Document: (tensor(19820), tensor(4521), tensor(16105), tensor(4004), tensor(15831), tensor(8878), tensor(11557), tensor(15736))\n",
      "\n",
      "Batch 53:\n",
      "Input IDs: torch.Size([8, 1133])\n",
      "Attention_mask: torch.Size([8, 1133])\n",
      "Labels: torch.Size([8, 1133, 13])\n",
      "Document: (tensor(14850), tensor(22172), tensor(9251), tensor(10925), tensor(18480), tensor(7713), tensor(18679), tensor(18119))\n",
      "\n",
      "Batch 54:\n",
      "Input IDs: torch.Size([8, 1109])\n",
      "Attention_mask: torch.Size([8, 1109])\n",
      "Labels: torch.Size([8, 1109, 13])\n",
      "Document: (tensor(10324), tensor(15587), tensor(10997), tensor(14348), tensor(13178), tensor(12705), tensor(10440), tensor(12995))\n",
      "\n",
      "Batch 55:\n",
      "Input IDs: torch.Size([8, 1953])\n",
      "Attention_mask: torch.Size([8, 1953])\n",
      "Labels: torch.Size([8, 1953, 13])\n",
      "Document: (tensor(10067), tensor(14274), tensor(17753), tensor(19582), tensor(12738), tensor(10731), tensor(12369), tensor(21582))\n",
      "\n",
      "Batch 56:\n",
      "Input IDs: torch.Size([8, 1655])\n",
      "Attention_mask: torch.Size([8, 1655])\n",
      "Labels: torch.Size([8, 1655, 13])\n",
      "Document: (tensor(15340), tensor(15969), tensor(16127), tensor(19706), tensor(13166), tensor(15554), tensor(15851), tensor(20147))\n",
      "\n",
      "Batch 57:\n",
      "Input IDs: torch.Size([8, 1047])\n",
      "Attention_mask: torch.Size([8, 1047])\n",
      "Labels: torch.Size([8, 1047, 13])\n",
      "Document: (tensor(10735), tensor(15716), tensor(13681), tensor(12313), tensor(9141), tensor(12865), tensor(6941), tensor(22377))\n",
      "\n",
      "Batch 58:\n",
      "Input IDs: torch.Size([8, 1587])\n",
      "Attention_mask: torch.Size([8, 1587])\n",
      "Labels: torch.Size([8, 1587, 13])\n",
      "Document: (tensor(19414), tensor(10625), tensor(18822), tensor(19397), tensor(10472), tensor(17858), tensor(22456), tensor(14537))\n",
      "\n",
      "Batch 59:\n",
      "Input IDs: torch.Size([8, 1332])\n",
      "Attention_mask: torch.Size([8, 1332])\n",
      "Labels: torch.Size([8, 1332, 13])\n",
      "Document: (tensor(11916), tensor(2672), tensor(14013), tensor(22653), tensor(10752), tensor(12155), tensor(14200), tensor(14491))\n",
      "\n",
      "Batch 60:\n",
      "Input IDs: torch.Size([8, 1094])\n",
      "Attention_mask: torch.Size([8, 1094])\n",
      "Labels: torch.Size([8, 1094, 13])\n",
      "Document: (tensor(19403), tensor(7735), tensor(20984), tensor(12069), tensor(16529), tensor(10008), tensor(14512), tensor(21755))\n",
      "\n",
      "Batch 61:\n",
      "Input IDs: torch.Size([8, 1457])\n",
      "Attention_mask: torch.Size([8, 1457])\n",
      "Labels: torch.Size([8, 1457, 13])\n",
      "Document: (tensor(7993), tensor(10014), tensor(20588), tensor(20322), tensor(17171), tensor(13202), tensor(17260), tensor(14376))\n",
      "\n",
      "Batch 62:\n",
      "Input IDs: torch.Size([8, 1348])\n",
      "Attention_mask: torch.Size([8, 1348])\n",
      "Labels: torch.Size([8, 1348, 13])\n",
      "Document: (tensor(5952), tensor(12868), tensor(13667), tensor(15714), tensor(20078), tensor(20812), tensor(18328), tensor(6622))\n",
      "\n",
      "Batch 63:\n",
      "Input IDs: torch.Size([8, 1540])\n",
      "Attention_mask: torch.Size([8, 1540])\n",
      "Labels: torch.Size([8, 1540, 13])\n",
      "Document: (tensor(15842), tensor(19240), tensor(21682), tensor(19836), tensor(9639), tensor(5964), tensor(20304), tensor(11160))\n",
      "\n",
      "Batch 64:\n",
      "Input IDs: torch.Size([8, 1201])\n",
      "Attention_mask: torch.Size([8, 1201])\n",
      "Labels: torch.Size([8, 1201, 13])\n",
      "Document: (tensor(21413), tensor(21109), tensor(12216), tensor(21882), tensor(19853), tensor(22146), tensor(22302), tensor(14539))\n",
      "\n",
      "Batch 65:\n",
      "Input IDs: torch.Size([8, 1053])\n",
      "Attention_mask: torch.Size([8, 1053])\n",
      "Labels: torch.Size([8, 1053, 13])\n",
      "Document: (tensor(15997), tensor(10597), tensor(22357), tensor(18159), tensor(18136), tensor(12106), tensor(18095), tensor(2790))\n",
      "\n",
      "Batch 66:\n",
      "Input IDs: torch.Size([8, 979])\n",
      "Attention_mask: torch.Size([8, 979])\n",
      "Labels: torch.Size([8, 979, 13])\n",
      "Document: (tensor(9223), tensor(17650), tensor(19694), tensor(12950), tensor(20337), tensor(18277), tensor(4509), tensor(19511))\n",
      "\n",
      "Batch 67:\n",
      "Input IDs: torch.Size([8, 1464])\n",
      "Attention_mask: torch.Size([8, 1464])\n",
      "Labels: torch.Size([8, 1464, 13])\n",
      "Document: (tensor(12679), tensor(8805), tensor(2054), tensor(13075), tensor(9711), tensor(9636), tensor(10016), tensor(17277))\n",
      "\n",
      "Batch 68:\n",
      "Input IDs: torch.Size([8, 1755])\n",
      "Attention_mask: torch.Size([8, 1755])\n",
      "Labels: torch.Size([8, 1755, 13])\n",
      "Document: (tensor(20383), tensor(10151), tensor(14740), tensor(12750), tensor(12588), tensor(8733), tensor(10783), tensor(10409))\n",
      "\n",
      "Batch 69:\n",
      "Input IDs: torch.Size([8, 1589])\n",
      "Attention_mask: torch.Size([8, 1589])\n",
      "Labels: torch.Size([8, 1589, 13])\n",
      "Document: (tensor(9797), tensor(20989), tensor(19548), tensor(20656), tensor(17001), tensor(12870), tensor(20378), tensor(17245))\n",
      "\n",
      "Batch 70:\n",
      "Input IDs: torch.Size([8, 948])\n",
      "Attention_mask: torch.Size([8, 948])\n",
      "Labels: torch.Size([8, 948, 13])\n",
      "Document: (tensor(12490), tensor(11240), tensor(21698), tensor(4669), tensor(11161), tensor(12819), tensor(21471), tensor(22443))\n",
      "\n",
      "Batch 71:\n",
      "Input IDs: torch.Size([8, 1003])\n",
      "Attention_mask: torch.Size([8, 1003])\n",
      "Labels: torch.Size([8, 1003, 13])\n",
      "Document: (tensor(20060), tensor(21793), tensor(11819), tensor(15437), tensor(14992), tensor(14196), tensor(9685), tensor(10010))\n",
      "\n",
      "Batch 72:\n",
      "Input IDs: torch.Size([8, 945])\n",
      "Attention_mask: torch.Size([8, 945])\n",
      "Labels: torch.Size([8, 945, 13])\n",
      "Document: (tensor(16816), tensor(20878), tensor(12193), tensor(11409), tensor(14065), tensor(22228), tensor(10846), tensor(17925))\n",
      "\n",
      "Batch 73:\n",
      "Input IDs: torch.Size([8, 1027])\n",
      "Attention_mask: torch.Size([8, 1027])\n",
      "Labels: torch.Size([8, 1027, 13])\n",
      "Document: (tensor(14349), tensor(8867), tensor(17306), tensor(6859), tensor(19284), tensor(18556), tensor(1175), tensor(11128))\n",
      "\n",
      "Batch 74:\n",
      "Input IDs: torch.Size([8, 1200])\n",
      "Attention_mask: torch.Size([8, 1200])\n",
      "Labels: torch.Size([8, 1200, 13])\n",
      "Document: (tensor(12625), tensor(13847), tensor(11605), tensor(10490), tensor(17457), tensor(16501), tensor(19072), tensor(14446))\n",
      "\n",
      "Batch 75:\n",
      "Input IDs: torch.Size([8, 1265])\n",
      "Attention_mask: torch.Size([8, 1265])\n",
      "Labels: torch.Size([8, 1265, 13])\n",
      "Document: (tensor(15742), tensor(17711), tensor(13092), tensor(11838), tensor(20302), tensor(16511), tensor(10836), tensor(10606))\n",
      "\n",
      "Batch 76:\n",
      "Input IDs: torch.Size([8, 1461])\n",
      "Attention_mask: torch.Size([8, 1461])\n",
      "Labels: torch.Size([8, 1461, 13])\n",
      "Document: (tensor(10055), tensor(13121), tensor(17038), tensor(21093), tensor(15332), tensor(10314), tensor(8631), tensor(18442))\n",
      "\n",
      "Batch 77:\n",
      "Input IDs: torch.Size([8, 1438])\n",
      "Attention_mask: torch.Size([8, 1438])\n",
      "Labels: torch.Size([8, 1438, 13])\n",
      "Document: (tensor(21042), tensor(9095), tensor(5662), tensor(9657), tensor(9803), tensor(20852), tensor(18307), tensor(22055))\n",
      "\n",
      "Batch 78:\n",
      "Input IDs: torch.Size([8, 1251])\n",
      "Attention_mask: torch.Size([8, 1251])\n",
      "Labels: torch.Size([8, 1251, 13])\n",
      "Document: (tensor(22225), tensor(14443), tensor(10956), tensor(14675), tensor(8910), tensor(13251), tensor(19618), tensor(21990))\n",
      "\n",
      "Batch 79:\n",
      "Input IDs: torch.Size([8, 1013])\n",
      "Attention_mask: torch.Size([8, 1013])\n",
      "Labels: torch.Size([8, 1013, 13])\n",
      "Document: (tensor(14050), tensor(20414), tensor(20029), tensor(17549), tensor(6174), tensor(14957), tensor(10059), tensor(11982))\n",
      "\n",
      "Batch 80:\n",
      "Input IDs: torch.Size([8, 962])\n",
      "Attention_mask: torch.Size([8, 962])\n",
      "Labels: torch.Size([8, 962, 13])\n",
      "Document: (tensor(9324), tensor(9741), tensor(18452), tensor(2780), tensor(7676), tensor(20223), tensor(18385), tensor(10396))\n",
      "\n",
      "Batch 81:\n",
      "Input IDs: torch.Size([8, 1266])\n",
      "Attention_mask: torch.Size([8, 1266])\n",
      "Labels: torch.Size([8, 1266, 13])\n",
      "Document: (tensor(10538), tensor(11262), tensor(19003), tensor(4040), tensor(6257), tensor(8995), tensor(18209), tensor(9755))\n",
      "\n",
      "Batch 82:\n",
      "Input IDs: torch.Size([8, 944])\n",
      "Attention_mask: torch.Size([8, 944])\n",
      "Labels: torch.Size([8, 944, 13])\n",
      "Document: (tensor(12405), tensor(19813), tensor(12299), tensor(20468), tensor(18055), tensor(19943), tensor(22438), tensor(11729))\n",
      "\n",
      "Batch 83:\n",
      "Input IDs: torch.Size([8, 911])\n",
      "Attention_mask: torch.Size([8, 911])\n",
      "Labels: torch.Size([8, 911, 13])\n",
      "Document: (tensor(13924), tensor(15622), tensor(11529), tensor(8982), tensor(19730), tensor(13908), tensor(15580), tensor(20082))\n",
      "\n",
      "Batch 84:\n",
      "Input IDs: torch.Size([8, 1440])\n",
      "Attention_mask: torch.Size([8, 1440])\n",
      "Labels: torch.Size([8, 1440, 13])\n",
      "Document: (tensor(20097), tensor(18640), tensor(4185), tensor(10859), tensor(20041), tensor(12137), tensor(16967), tensor(10053))\n",
      "\n",
      "Batch 85:\n",
      "Input IDs: torch.Size([8, 1443])\n",
      "Attention_mask: torch.Size([8, 1443])\n",
      "Labels: torch.Size([8, 1443, 13])\n",
      "Document: (tensor(19112), tensor(21142), tensor(14500), tensor(11907), tensor(9872), tensor(12392), tensor(14613), tensor(10232))\n",
      "\n",
      "Batch 86:\n",
      "Input IDs: torch.Size([8, 1148])\n",
      "Attention_mask: torch.Size([8, 1148])\n",
      "Labels: torch.Size([8, 1148, 13])\n",
      "Document: (tensor(12603), tensor(11942), tensor(17415), tensor(14037), tensor(15148), tensor(13722), tensor(22297), tensor(16063))\n",
      "\n",
      "Batch 87:\n",
      "Input IDs: torch.Size([8, 1177])\n",
      "Attention_mask: torch.Size([8, 1177])\n",
      "Labels: torch.Size([8, 1177, 13])\n",
      "Document: (tensor(6531), tensor(18326), tensor(9664), tensor(5796), tensor(15753), tensor(9740), tensor(15445), tensor(20774))\n",
      "\n",
      "Batch 88:\n",
      "Input IDs: torch.Size([8, 1141])\n",
      "Attention_mask: torch.Size([8, 1141])\n",
      "Labels: torch.Size([8, 1141, 13])\n",
      "Document: (tensor(19921), tensor(11585), tensor(11250), tensor(19745), tensor(12187), tensor(21206), tensor(9652), tensor(11210))\n",
      "\n",
      "Batch 89:\n",
      "Input IDs: torch.Size([8, 1031])\n",
      "Attention_mask: torch.Size([8, 1031])\n",
      "Labels: torch.Size([8, 1031, 13])\n",
      "Document: (tensor(17456), tensor(21563), tensor(10648), tensor(9730), tensor(19692), tensor(9854), tensor(11611), tensor(20014))\n",
      "\n",
      "Batch 90:\n",
      "Input IDs: torch.Size([8, 916])\n",
      "Attention_mask: torch.Size([8, 916])\n",
      "Labels: torch.Size([8, 916, 13])\n",
      "Document: (tensor(5944), tensor(5085), tensor(18627), tensor(16769), tensor(20572), tensor(4913), tensor(21392), tensor(21824))\n",
      "\n",
      "Batch 91:\n",
      "Input IDs: torch.Size([8, 1028])\n",
      "Attention_mask: torch.Size([8, 1028])\n",
      "Labels: torch.Size([8, 1028, 13])\n",
      "Document: (tensor(17722), tensor(21090), tensor(19399), tensor(13906), tensor(2802), tensor(19170), tensor(5910), tensor(12759))\n",
      "\n",
      "Batch 92:\n",
      "Input IDs: torch.Size([8, 1070])\n",
      "Attention_mask: torch.Size([8, 1070])\n",
      "Labels: torch.Size([8, 1070, 13])\n",
      "Document: (tensor(22037), tensor(10457), tensor(15396), tensor(14819), tensor(9840), tensor(17644), tensor(12287), tensor(10431))\n",
      "\n",
      "Batch 93:\n",
      "Input IDs: torch.Size([8, 1433])\n",
      "Attention_mask: torch.Size([8, 1433])\n",
      "Labels: torch.Size([8, 1433, 13])\n",
      "Document: (tensor(13648), tensor(12670), tensor(13160), tensor(21052), tensor(10463), tensor(17976), tensor(14314), tensor(10255))\n",
      "\n",
      "Batch 94:\n",
      "Input IDs: torch.Size([8, 1230])\n",
      "Attention_mask: torch.Size([8, 1230])\n",
      "Labels: torch.Size([8, 1230, 13])\n",
      "Document: (tensor(13103), tensor(9989), tensor(15021), tensor(12662), tensor(15070), tensor(16973), tensor(19199), tensor(12502))\n",
      "\n",
      "Batch 95:\n",
      "Input IDs: torch.Size([8, 968])\n",
      "Attention_mask: torch.Size([8, 968])\n",
      "Labels: torch.Size([8, 968, 13])\n",
      "Document: (tensor(5296), tensor(15322), tensor(14133), tensor(10392), tensor(17201), tensor(20310), tensor(11591), tensor(17692))\n",
      "\n",
      "Batch 96:\n",
      "Input IDs: torch.Size([8, 1263])\n",
      "Attention_mask: torch.Size([8, 1263])\n",
      "Labels: torch.Size([8, 1263, 13])\n",
      "Document: (tensor(269), tensor(13376), tensor(16151), tensor(12981), tensor(112), tensor(21213), tensor(16208), tensor(6074))\n",
      "\n",
      "Batch 97:\n",
      "Input IDs: torch.Size([8, 1570])\n",
      "Attention_mask: torch.Size([8, 1570])\n",
      "Labels: torch.Size([8, 1570, 13])\n",
      "Document: (tensor(16396), tensor(10515), tensor(21124), tensor(17836), tensor(16044), tensor(14173), tensor(14316), tensor(6124))\n",
      "\n",
      "Batch 98:\n",
      "Input IDs: torch.Size([8, 1053])\n",
      "Attention_mask: torch.Size([8, 1053])\n",
      "Labels: torch.Size([8, 1053, 13])\n",
      "Document: (tensor(21529), tensor(18570), tensor(17683), tensor(12354), tensor(16679), tensor(20917), tensor(12288), tensor(8871))\n",
      "\n",
      "Batch 99:\n",
      "Input IDs: torch.Size([8, 958])\n",
      "Attention_mask: torch.Size([8, 958])\n",
      "Labels: torch.Size([8, 958, 13])\n",
      "Document: (tensor(11260), tensor(13591), tensor(22550), tensor(9795), tensor(13886), tensor(14900), tensor(21499), tensor(17647))\n",
      "\n",
      "Batch 100:\n",
      "Input IDs: torch.Size([8, 1338])\n",
      "Attention_mask: torch.Size([8, 1338])\n",
      "Labels: torch.Size([8, 1338, 13])\n",
      "Document: (tensor(21335), tensor(20902), tensor(20004), tensor(9551), tensor(12447), tensor(16688), tensor(11448), tensor(13831))\n",
      "\n",
      "Batch 101:\n",
      "Input IDs: torch.Size([8, 1191])\n",
      "Attention_mask: torch.Size([8, 1191])\n",
      "Labels: torch.Size([8, 1191, 13])\n",
      "Document: (tensor(4486), tensor(22125), tensor(10467), tensor(15362), tensor(16012), tensor(12512), tensor(15724), tensor(7222))\n",
      "\n",
      "Batch 102:\n",
      "Input IDs: torch.Size([8, 1152])\n",
      "Attention_mask: torch.Size([8, 1152])\n",
      "Labels: torch.Size([8, 1152, 13])\n",
      "Document: (tensor(16828), tensor(20421), tensor(22273), tensor(21488), tensor(19631), tensor(18619), tensor(10720), tensor(10458))\n",
      "\n",
      "Batch 103:\n",
      "Input IDs: torch.Size([8, 1329])\n",
      "Attention_mask: torch.Size([8, 1329])\n",
      "Labels: torch.Size([8, 1329, 13])\n",
      "Document: (tensor(17140), tensor(2732), tensor(10656), tensor(10495), tensor(13878), tensor(7115), tensor(21699), tensor(13825))\n",
      "\n",
      "Batch 104:\n",
      "Input IDs: torch.Size([8, 724])\n",
      "Attention_mask: torch.Size([8, 724])\n",
      "Labels: torch.Size([8, 724, 13])\n",
      "Document: (tensor(18085), tensor(18885), tensor(20496), tensor(8833), tensor(16528), tensor(21783), tensor(13769), tensor(17191))\n",
      "\n",
      "Batch 105:\n",
      "Input IDs: torch.Size([8, 1449])\n",
      "Attention_mask: torch.Size([8, 1449])\n",
      "Labels: torch.Size([8, 1449, 13])\n",
      "Document: (tensor(19086), tensor(17113), tensor(13628), tensor(17599), tensor(4381), tensor(19101), tensor(18781), tensor(10317))\n",
      "\n",
      "Batch 106:\n",
      "Input IDs: torch.Size([8, 847])\n",
      "Attention_mask: torch.Size([8, 847])\n",
      "Labels: torch.Size([8, 847, 13])\n",
      "Document: (tensor(14310), tensor(14505), tensor(17847), tensor(21149), tensor(20842), tensor(19505), tensor(7865), tensor(16263))\n",
      "\n",
      "Batch 107:\n",
      "Input IDs: torch.Size([8, 1334])\n",
      "Attention_mask: torch.Size([8, 1334])\n",
      "Labels: torch.Size([8, 1334, 13])\n",
      "Document: (tensor(17098), tensor(10946), tensor(21538), tensor(14840), tensor(20589), tensor(12057), tensor(15641), tensor(21763))\n",
      "\n",
      "Batch 108:\n",
      "Input IDs: torch.Size([8, 1177])\n",
      "Attention_mask: torch.Size([8, 1177])\n",
      "Labels: torch.Size([8, 1177, 13])\n",
      "Document: (tensor(19547), tensor(10561), tensor(9582), tensor(10114), tensor(21742), tensor(11714), tensor(11430), tensor(13342))\n",
      "\n",
      "Batch 109:\n",
      "Input IDs: torch.Size([8, 979])\n",
      "Attention_mask: torch.Size([8, 979])\n",
      "Labels: torch.Size([8, 979, 13])\n",
      "Document: (tensor(4868), tensor(22206), tensor(10721), tensor(11933), tensor(13532), tensor(16487), tensor(11399), tensor(14966))\n",
      "\n",
      "Batch 110:\n",
      "Input IDs: torch.Size([8, 1011])\n",
      "Attention_mask: torch.Size([8, 1011])\n",
      "Labels: torch.Size([8, 1011, 13])\n",
      "Document: (tensor(10588), tensor(16556), tensor(16821), tensor(19725), tensor(10651), tensor(18949), tensor(13627), tensor(19804))\n",
      "\n",
      "Batch 111:\n",
      "Input IDs: torch.Size([8, 1050])\n",
      "Attention_mask: torch.Size([8, 1050])\n",
      "Labels: torch.Size([8, 1050, 13])\n",
      "Document: (tensor(10761), tensor(10401), tensor(9758), tensor(18682), tensor(13153), tensor(19344), tensor(15791), tensor(19625))\n",
      "\n",
      "Batch 112:\n",
      "Input IDs: torch.Size([8, 780])\n",
      "Attention_mask: torch.Size([8, 780])\n",
      "Labels: torch.Size([8, 780, 13])\n",
      "Document: (tensor(5209), tensor(14713), tensor(10400), tensor(15855), tensor(13551), tensor(4799), tensor(20031), tensor(16161))\n",
      "\n",
      "Batch 113:\n",
      "Input IDs: torch.Size([8, 1092])\n",
      "Attention_mask: torch.Size([8, 1092])\n",
      "Labels: torch.Size([8, 1092, 13])\n",
      "Document: (tensor(1790), tensor(20569), tensor(10030), tensor(10902), tensor(18600), tensor(9724), tensor(21923), tensor(11705))\n",
      "\n",
      "Batch 114:\n",
      "Input IDs: torch.Size([8, 1555])\n",
      "Attention_mask: torch.Size([8, 1555])\n",
      "Labels: torch.Size([8, 1555, 13])\n",
      "Document: (tensor(22677), tensor(15915), tensor(12326), tensor(21418), tensor(13649), tensor(15162), tensor(10106), tensor(13556))\n",
      "\n",
      "Batch 115:\n",
      "Input IDs: torch.Size([8, 1351])\n",
      "Attention_mask: torch.Size([8, 1351])\n",
      "Labels: torch.Size([8, 1351, 13])\n",
      "Document: (tensor(20987), tensor(15740), tensor(19659), tensor(14625), tensor(9829), tensor(21891), tensor(14010), tensor(6577))\n",
      "\n",
      "Batch 116:\n",
      "Input IDs: torch.Size([8, 1275])\n",
      "Attention_mask: torch.Size([8, 1275])\n",
      "Labels: torch.Size([8, 1275, 13])\n",
      "Document: (tensor(21269), tensor(8584), tensor(21612), tensor(13800), tensor(19241), tensor(9140), tensor(5621), tensor(13136))\n",
      "\n",
      "Batch 117:\n",
      "Input IDs: torch.Size([8, 1359])\n",
      "Attention_mask: torch.Size([8, 1359])\n",
      "Labels: torch.Size([8, 1359, 13])\n",
      "Document: (tensor(9158), tensor(20561), tensor(18353), tensor(4413), tensor(19615), tensor(4295), tensor(21740), tensor(12304))\n",
      "\n",
      "Batch 118:\n",
      "Input IDs: torch.Size([8, 1519])\n",
      "Attention_mask: torch.Size([8, 1519])\n",
      "Labels: torch.Size([8, 1519, 13])\n",
      "Document: (tensor(10865), tensor(16773), tensor(16320), tensor(8033), tensor(18901), tensor(12186), tensor(14191), tensor(13754))\n",
      "\n",
      "Batch 119:\n",
      "Input IDs: torch.Size([8, 1743])\n",
      "Attention_mask: torch.Size([8, 1743])\n",
      "Labels: torch.Size([8, 1743, 13])\n",
      "Document: (tensor(13482), tensor(21224), tensor(9115), tensor(21554), tensor(8976), tensor(15543), tensor(13046), tensor(20180))\n",
      "\n",
      "Batch 120:\n",
      "Input IDs: torch.Size([8, 1244])\n",
      "Attention_mask: torch.Size([8, 1244])\n",
      "Labels: torch.Size([8, 1244, 13])\n",
      "Document: (tensor(12748), tensor(12858), tensor(19418), tensor(13414), tensor(16678), tensor(19482), tensor(4191), tensor(17067))\n",
      "\n",
      "Batch 121:\n",
      "Input IDs: torch.Size([8, 2073])\n",
      "Attention_mask: torch.Size([8, 2073])\n",
      "Labels: torch.Size([8, 2073, 13])\n",
      "Document: (tensor(22153), tensor(10404), tensor(8316), tensor(18501), tensor(12541), tensor(11474), tensor(5922), tensor(11670))\n",
      "\n",
      "Batch 122:\n",
      "Input IDs: torch.Size([8, 1030])\n",
      "Attention_mask: torch.Size([8, 1030])\n",
      "Labels: torch.Size([8, 1030, 13])\n",
      "Document: (tensor(20387), tensor(17531), tensor(5067), tensor(22210), tensor(15806), tensor(10064), tensor(8123), tensor(17940))\n",
      "\n",
      "Batch 123:\n",
      "Input IDs: torch.Size([8, 925])\n",
      "Attention_mask: torch.Size([8, 925])\n",
      "Labels: torch.Size([8, 925, 13])\n",
      "Document: (tensor(19386), tensor(17768), tensor(4750), tensor(19109), tensor(17231), tensor(19514), tensor(20188), tensor(11352))\n",
      "\n",
      "Batch 124:\n",
      "Input IDs: torch.Size([8, 1663])\n",
      "Attention_mask: torch.Size([8, 1663])\n",
      "Labels: torch.Size([8, 1663, 13])\n",
      "Document: (tensor(15938), tensor(18496), tensor(17842), tensor(21236), tensor(11213), tensor(10359), tensor(19310), tensor(14436))\n",
      "\n",
      "Batch 125:\n",
      "Input IDs: torch.Size([8, 1492])\n",
      "Attention_mask: torch.Size([8, 1492])\n",
      "Labels: torch.Size([8, 1492, 13])\n",
      "Document: (tensor(6085), tensor(16425), tensor(13643), tensor(15212), tensor(22672), tensor(14581), tensor(14955), tensor(19287))\n",
      "\n",
      "Batch 126:\n",
      "Input IDs: torch.Size([8, 1042])\n",
      "Attention_mask: torch.Size([8, 1042])\n",
      "Labels: torch.Size([8, 1042, 13])\n",
      "Document: (tensor(21723), tensor(12943), tensor(14185), tensor(9113), tensor(15707), tensor(17710), tensor(13116), tensor(10526))\n",
      "\n",
      "Batch 127:\n",
      "Input IDs: torch.Size([8, 1332])\n",
      "Attention_mask: torch.Size([8, 1332])\n",
      "Labels: torch.Size([8, 1332, 13])\n",
      "Document: (tensor(12883), tensor(16077), tensor(7265), tensor(6187), tensor(14068), tensor(14337), tensor(10659), tensor(14984))\n",
      "\n",
      "Batch 128:\n",
      "Input IDs: torch.Size([6, 1050])\n",
      "Attention_mask: torch.Size([6, 1050])\n",
      "Labels: torch.Size([6, 1050, 13])\n",
      "Document: (tensor(12295), tensor(16143), tensor(21153), tensor(5236), tensor(15782), tensor(17745))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Uncomment to check'''\n",
    "for i, (input_ids, attention_mask, labels, doc) in enumerate(val_dataloader):\n",
    "     print(f'Batch {i + 1}:')\n",
    "     print('Input IDs:', input_ids.size())\n",
    "     print('Attention_mask:', attention_mask.size())\n",
    "     print('Labels:', labels.size())\n",
    "     print('Document:', doc)\n",
    "     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "m8iohHD7P0lJ"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F-3GgKnWP0lJ"
   },
   "outputs": [],
   "source": [
    "def val(model, custom_val, batch_size, custom_collate, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    avg_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        val_score = {'f5': 0, 'recall': 0, 'precision': 0}\n",
    "        val_dataloader = DataLoader(custom_val, batch_size = batch_size, collate_fn = custom_collate, shuffle = False)\n",
    "\n",
    "        for batch, (input_ids, attention_mask, labels, doc) in enumerate(val_dataloader):\n",
    "\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            results = compute_metrics(outputs, labels)\n",
    "\n",
    "            val_loss += loss\n",
    "            val_score['f5'] += results['f5']\n",
    "            val_score['recall'] += results['recall']\n",
    "            val_score['precision'] += results['precision']\n",
    "\n",
    "            if batch%200 == 0 or batch+1 == len(val_dataloader):\n",
    "                print(\"********** For Validation Set **********\")\n",
    "                print(f\"Completed {batch+1}/{len(val_dataloader)}, with current val_loss: {loss: .4e},\\n current results:{results}\")\n",
    "\n",
    "    avg_val_loss = val_loss / len(custom_val)\n",
    "    for k in val_score:\n",
    "        val_score[k] /= len(val_dataloader)\n",
    "    # avg_val_score = val_score/len(val_dataloader)\n",
    "\n",
    "    print(f\"Average val_loss: {avg_val_loss: .4e}, avgerage val_score = {val_score}\")\n",
    "\n",
    "    return avg_val_loss, val_score['f5']    #Return only f5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yo5SymfvP0lJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def train(model, custom_train, custom_val, batch_size, custom_collate, epochs, optimizer, criterion,  device):\n",
    "\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_score = -float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "        avg_train_loss = 0\n",
    "        train_loss = 0\n",
    "        train_score = {'f5': 0, 'recall': 0, 'precision': 0}\n",
    "\n",
    "\n",
    "        train_dataloader = DataLoader(custom_train, batch_size = batch_size, collate_fn = custom_collate, shuffle = True)\n",
    "        print('Starting training...')\n",
    "\n",
    "        for batch, (input_ids, attention_mask, labels, doc) in enumerate(train_dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask).logits\n",
    "            # print(outputs.size())\n",
    "            # print(labels.size())\n",
    "            # print(outputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print(f\"Loss: {loss:.4e}\")\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "            results = compute_metrics(outputs, labels)\n",
    "            train_loss += loss\n",
    "            train_score['f5']+= results['f5']\n",
    "            train_score['recall'] += results['recall']\n",
    "            train_score['precision'] += results['precision']\n",
    "\n",
    "\n",
    "\n",
    "            if batch%200 == 0 or batch+1 == len(train_dataloader):\n",
    "                results = compute_metrics(outputs, labels)\n",
    "                print(f\"Completed {batch+1}/{len(train_dataloader)}, with current train_loss: {loss: .4e},\\n current results:{results}\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(custom_train)\n",
    "        for k in train_score:\n",
    "            train_score[k] /= len(train_dataloader)\n",
    "        #avg_train_score = train_score / len(train_dataloader)\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Average train_loss = {avg_train_loss: .4e}, average train_score = {train_score}\")\n",
    "\n",
    "        print()\n",
    "        print(\"Starting to validate\")\n",
    "        val_loss, val_score = val(model, custom_val, batch_size, custom_collate, criterion, device)\n",
    "\n",
    "        print(f\"Epoch time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'T5_small_LoRA_best_loss.pt')\n",
    "\n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            torch.save(model.state_dict(), 'T5_small_LoRA_best_score.pt')\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), f'T5_small_LoRA_{epochs}.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4e3oZGBP0lK"
   },
   "source": [
    "Running the function below will output the loss and results every 200 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Completed 1/1447, with current train_loss:  8.7608e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 201/1447, with current train_loss:  1.6848e-03,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 401/1447, with current train_loss:  1.0093e-03,\n",
      " current results:{'f5': 0.801762114537445, 'recall': 1.0, 'precision': 0.13461538461538464}\n",
      "Completed 601/1447, with current train_loss:  7.9055e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 801/1447, with current train_loss:  1.1167e-03,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1001/1447, with current train_loss:  7.7330e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1201/1447, with current train_loss:  8.7933e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1401/1447, with current train_loss:  5.6079e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 1447/1447, with current train_loss:  1.7852e-03,\n",
      " current results:{'f5': 0.8863636363636365, 'recall': 1.0, 'precision': 0.23076923076923078}\n",
      "\n",
      "Epoch 1/5: Average train_loss =  2.5637e-04, average train_score = {'f5': 0.72777984383831, 'recall': 1.0, 'precision': 0.0975083284602983}\n",
      "\n",
      "Starting to validate\n",
      "********** For Validation Set **********\n",
      "Completed 1/256, with current val_loss:  1.0984e-03,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 201/256, with current val_loss:  5.6426e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 256/256, with current val_loss:  1.0203e-03,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Average val_loss:  1.6773e-04, avgerage val_score = {'f5': 0.7332354425976093, 'recall': 1.0, 'precision': 0.10025415665064095}\n",
      "Epoch time: 14m 34s\n",
      "\n",
      "Starting training...\n",
      "Completed 1/1447, with current train_loss:  7.0727e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 201/1447, with current train_loss:  8.3709e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 401/1447, with current train_loss:  4.4341e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 601/1447, with current train_loss:  4.4002e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 801/1447, with current train_loss:  3.3614e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1001/1447, with current train_loss:  5.4953e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1201/1447, with current train_loss:  2.8918e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 1401/1447, with current train_loss:  2.8999e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1447/1447, with current train_loss:  5.0214e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "\n",
      "Epoch 2/5: Average train_loss =  1.2036e-04, average train_score = {'f5': 0.7274443913187115, 'recall': 1.0, 'precision': 0.09746181312352722}\n",
      "\n",
      "Starting to validate\n",
      "********** For Validation Set **********\n",
      "Completed 1/256, with current val_loss:  5.3821e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 201/256, with current val_loss:  2.7516e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 256/256, with current val_loss:  4.9449e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Average val_loss:  8.1519e-05, avgerage val_score = {'f5': 0.7331742416406303, 'recall': 1.0, 'precision': 0.10021659655448711}\n",
      "Epoch time: 14m 17s\n",
      "\n",
      "Starting training...\n",
      "Completed 1/1447, with current train_loss:  3.2898e-04,\n",
      " current results:{'f5': 0.8253968253968254, 'recall': 1.0, 'precision': 0.15384615384615385}\n",
      "Completed 201/1447, with current train_loss:  2.3316e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 401/1447, with current train_loss:  2.1801e-04,\n",
      " current results:{'f5': 0.801762114537445, 'recall': 1.0, 'precision': 0.13461538461538464}\n",
      "Completed 601/1447, with current train_loss:  2.9973e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 801/1447, with current train_loss:  2.3052e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1001/1447, with current train_loss:  2.4634e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1201/1447, with current train_loss:  1.5469e-04,\n",
      " current results:{'f5': 0.8253968253968254, 'recall': 1.0, 'precision': 0.15384615384615385}\n",
      "Completed 1401/1447, with current train_loss:  1.9288e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 1447/1447, with current train_loss:  4.1924e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "\n",
      "Epoch 3/5: Average train_loss =  6.0901e-05, average train_score = {'f5': 0.7272447751645601, 'recall': 1.0, 'precision': 0.09744540186834619}\n",
      "\n",
      "Starting to validate\n",
      "********** For Validation Set **********\n",
      "Completed 1/256, with current val_loss:  3.0782e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 201/256, with current val_loss:  1.5570e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 256/256, with current val_loss:  2.7447e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Average val_loss:  4.6144e-05, avgerage val_score = {'f5': 0.7331849173458079, 'recall': 1.0, 'precision': 0.10022285657051276}\n",
      "Epoch time: 14m 33s\n",
      "\n",
      "Starting training...\n",
      "Completed 1/1447, with current train_loss:  2.4033e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 201/1447, with current train_loss:  1.0881e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "Completed 401/1447, with current train_loss:  1.9339e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 601/1447, with current train_loss:  6.7099e-05,\n",
      " current results:{'f5': 0.8447653429602889, 'recall': 1.0, 'precision': 0.17307692307692307}\n",
      "Completed 801/1447, with current train_loss:  1.3859e-04,\n",
      " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
      "Completed 1001/1447, with current train_loss:  1.5740e-04,\n",
      " current results:{'f5': 0.8447653429602889, 'recall': 1.0, 'precision': 0.17307692307692307}\n",
      "Completed 1201/1447, with current train_loss:  1.4610e-04,\n",
      " current results:{'f5': 0.8253968253968254, 'recall': 1.0, 'precision': 0.15384615384615385}\n",
      "Completed 1401/1447, with current train_loss:  1.4352e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 1447/1447, with current train_loss:  3.1476e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "\n",
      "Epoch 4/5: Average train_loss =  4.0578e-05, average train_score = {'f5': 0.7273847498967977, 'recall': 1.0, 'precision': 0.09746865953673176}\n",
      "\n",
      "Starting to validate\n",
      "********** For Validation Set **********\n",
      "Completed 1/256, with current val_loss:  2.4521e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 201/256, with current val_loss:  1.2374e-04,\n",
      " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
      "********** For Validation Set **********\n",
      "Completed 256/256, with current val_loss:  2.1434e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Average val_loss:  3.6585e-05, avgerage val_score = {'f5': 0.7334365758695514, 'recall': 0.9996744791666667, 'precision': 0.10040894977418409}\n",
      "Epoch time: 13m 59s\n",
      "\n",
      "Starting training...\n",
      "Completed 1/1447, with current train_loss:  1.1753e-04,\n",
      " current results:{'f5': 0.8609271523178806, 'recall': 1.0, 'precision': 0.1923076923076923}\n",
      "Completed 201/1447, with current train_loss:  1.6303e-04,\n",
      " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
      "Completed 401/1447, with current train_loss:  1.7568e-04,\n",
      " current results:{'f5': 0.8447653429602889, 'recall': 1.0, 'precision': 0.17307692307692307}\n",
      "Completed 601/1447, with current train_loss:  1.4481e-04,\n",
      " current results:{'f5': 0.6890210924824229, 'recall': 1.0, 'precision': 0.07852564102564102}\n",
      "Completed 801/1447, with current train_loss:  1.6293e-04,\n",
      " current results:{'f5': 0.6945412311265969, 'recall': 1.0, 'precision': 0.08041958041958042}\n",
      "Completed 1001/1447, with current train_loss:  1.0948e-04,\n",
      " current results:{'f5': 0.7801476329051034, 'recall': 0.95, 'precision': 0.14262820512820512}\n",
      "Completed 1201/1447, with current train_loss:  1.4219e-04,\n",
      " current results:{'f5': 0.7623862487360971, 'recall': 1.0, 'precision': 0.10984848484848483}\n",
      "Completed 1401/1447, with current train_loss:  1.4163e-04,\n",
      " current results:{'f5': 0.8508982379613155, 'recall': 1.0, 'precision': 0.17998737373737372}\n",
      "Completed 1447/1447, with current train_loss:  2.5780e-04,\n",
      " current results:{'f5': 0.7878787878787878, 'recall': 1.0, 'precision': 0.125}\n",
      "\n",
      "Epoch 5/5: Average train_loss =  3.5893e-05, average train_score = {'f5': 0.7366952440244667, 'recall': 0.9925334024418367, 'precision': 0.10394929208854577}\n",
      "\n",
      "Starting to validate\n",
      "********** For Validation Set **********\n",
      "Completed 1/256, with current val_loss:  2.3569e-04,\n",
      " current results:{'f5': 0.7563445756842655, 'recall': 0.9166666666666666, 'precision': 0.1407828282828283}\n",
      "********** For Validation Set **********\n",
      "Completed 201/256, with current val_loss:  1.1931e-04,\n",
      " current results:{'f5': 0.7510182207931403, 'recall': 0.9166666666666666, 'precision': 0.1361111111111111}\n",
      "********** For Validation Set **********\n",
      "Completed 256/256, with current val_loss:  2.0512e-04,\n",
      " current results:{'f5': 0.7328859060402685, 'recall': 1.0, 'precision': 0.09545454545454546}\n",
      "Average val_loss:  3.5131e-05, avgerage val_score = {'f5': 0.7622816068970627, 'recall': 0.9610886346726182, 'precision': 0.1282938307352369}\n",
      "Epoch time: 14m 33s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "epochs = 5\n",
    "criterion = FocalLoss()\n",
    "\n",
    "train(model, custom_train, custom_val, batch_size, custom_collate, epochs, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oX_FQkNBhLwY"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'T5LoRAmodel_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kE77eyX7HdCA",
    "outputId": "986bee1d-56ac-43a9-92dc-3cbef74fc24b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      2\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT5LoRAmodel_full.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('T5LoRAmodel_full.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "fUX0wbd9Hr2-",
    "outputId": "c902e4a9-eba0-4f7f-8352-4bba5ed7c28d"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_888ce3fd-21b2-4763-a25a-26abcaec961c\", \"T5_small_LoRA_5.pt\", 144546743)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_3007ac78-940a-42e0-bfe8-a512725ea743\", \"T5_small_LoRA_best_loss.pt\", 144547583)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_57b0b477-ebf5-4cce-8ee0-73ad74832dbe\", \"T5_small_LoRA_best_score.pt\", 144547664)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download('T5_small_LoRA_5.pt')\n",
    "files.download('T5_small_LoRA_best_loss.pt')\n",
    "files.download('T5_small_LoRA_best_score.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sZ6pYKHP0lK"
   },
   "source": [
    "# Converting from predictions to NER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXvzx6qnitTa"
   },
   "outputs": [],
   "source": [
    "# load model for testing\n",
    "#model = torch.load('T5model_full.pth')\n",
    "#model.eval()  # Set the model to evaluation mode"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07234c7b51544c27a05ecffa91cddfbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08839243a92f4a55a9c79573c54e34e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aec0dd539324488ab0bda7e20fb5e4ee",
      "placeholder": "​",
      "style": "IPY_MODEL_6c5a6c4de11a4cdca36b842148ff1f60",
      "value": "Map (num_proc=3): 100%"
     }
    },
    "2845269df4af4d969f55ff24fcb22d6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a140a9d5f8494b74aae44b6559a35612",
      "placeholder": "​",
      "style": "IPY_MODEL_ef189afc4e064787a1ad4f503dc66f77",
      "value": "Map (num_proc=3): 100%"
     }
    },
    "5c23a733d360454087c8b51862ef2573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "633cf20038dd4c2a83c54f3bc83c076b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3992ca9a85849ea9b807e6d2f36120a",
      "max": 1022,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_658044d033914f9f8899b08733afd0a7",
      "value": 1022
     }
    },
    "658044d033914f9f8899b08733afd0a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c5a6c4de11a4cdca36b842148ff1f60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b75520d32464159aaf1df18a5d79557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2845269df4af4d969f55ff24fcb22d6c",
       "IPY_MODEL_633cf20038dd4c2a83c54f3bc83c076b",
       "IPY_MODEL_b3550a6e502e4a879d976b058aee08f4"
      ],
      "layout": "IPY_MODEL_a5949a52513341a8bcefec74813a0975"
     }
    },
    "7f850617a1244e8c847599cfe3d9864d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c80fbe0e7ccc49cca7545def9ae6d0f9",
      "max": 5785,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c23a733d360454087c8b51862ef2573",
      "value": 5785
     }
    },
    "934d8a50afe94ec5aa281a71a0dd835f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a140a9d5f8494b74aae44b6559a35612": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5949a52513341a8bcefec74813a0975": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aec0dd539324488ab0bda7e20fb5e4ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3550a6e502e4a879d976b058aee08f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7ed24318c5d44adb938faf7353c47a6",
      "placeholder": "​",
      "style": "IPY_MODEL_07234c7b51544c27a05ecffa91cddfbb",
      "value": " 1022/1022 [00:03&lt;00:00, 515.79 examples/s]"
     }
    },
    "baa2afc3a2724969b0b170403e0f96d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbd2e8350d8a432da85cf9d1a2c183dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_934d8a50afe94ec5aa281a71a0dd835f",
      "placeholder": "​",
      "style": "IPY_MODEL_baa2afc3a2724969b0b170403e0f96d0",
      "value": " 5785/5785 [00:15&lt;00:00, 71.60 examples/s]"
     }
    },
    "c3992ca9a85849ea9b807e6d2f36120a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7ed24318c5d44adb938faf7353c47a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c80fbe0e7ccc49cca7545def9ae6d0f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d43e2ac16a734dda8a0e918c463c1ad2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef189afc4e064787a1ad4f503dc66f77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2206b9a9fe641b9a723f30b07a1e435": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_08839243a92f4a55a9c79573c54e34e9",
       "IPY_MODEL_7f850617a1244e8c847599cfe3d9864d",
       "IPY_MODEL_bbd2e8350d8a432da85cf9d1a2c183dd"
      ],
      "layout": "IPY_MODEL_d43e2ac16a734dda8a0e918c463c1ad2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
